Local Chatbot using DialoGPT

ğŸ“„ Project Summary
This is a general-purpose conversational AI chatbot built using the pre-trained DialoGPT-medium model from Microsoft. The model runs locally on CPU using PyTorch and the Hugging Face Transformers library. It simulates human-like dialogue by maintaining chat history for context.

ğŸ› ï¸ Features

ğŸ¤– Uses DialoGPT-medium for generating natural replies. DialoGPT-medium is a 345 million parameter conversational AI model based on GPT-2, designed for generating human-like dialogue.

ğŸ§  Maintains short-term memory using tokenized chat history

ğŸ’¬ Multi-turn dialogue with varied responses

ğŸ” Continues conversation until the user quits

ğŸª¶ Lightweight and CLI-based for ease of use on limited hardware

ğŸš€ How It Works
Loads the pre-trained DialoGPT-medium model and tokenizer.

Tokenizes user input and maintains a running history of conversation.

Uses generate() with sampling (top_k, top_p, temperature) for diverse responses.

Decodes and prints model responses in a loop.

âš ï¸ Limitations
The model may produce irrelevant or nonsensical replies, especially in longer conversations.

Due to limited computing resources, a larger or fine-tuned model could not be used. This results in weaker performance, especially in context retention and coherence.

Works best for general small talk, not for domain-specific tasks.

ğŸ“ˆ Future Improvements
Add web UI using React and FastAPI.

Replace DialoGPT with a more advanced or fine-tuned model (e.g., LLaMA, Falcon, GPT-Neo).

Enable long-term memory or file-based chat history.

Fine-tune on specific datasets to improve domain-specific performance (e.g., movie reviews, tech support).
